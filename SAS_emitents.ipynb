{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAS_emitents",
      "provenance": [],
      "collapsed_sections": [
        "MQlenkUZl4E7",
        "QNNS74AxJW_A",
        "t_2jIY11JN99",
        "-hjEFz2ZJo-C",
        "7B1EB9jqUQaA",
        "m3pIezkIpP71",
        "HdZHQFgikf3_",
        "nZ2ui4o7mYKi"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arina1308/SAS_Text_Project/blob/main/SAS_emitents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdqacc5kLKSc",
        "outputId": "851b842c-8edc-4ad5-edf2-242f53122ff1"
      },
      "source": [
        "!pip install pymorphy2\n",
        "!pip install natasha\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import compress\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import nltk\n",
        "warnings.filterwarnings('ignore')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pymorphy2\n",
        "nltk.download('punkt')\n",
        "from natasha import MorphVocab, NamesExtractor\n",
        "\n",
        "py2 = pymorphy2.MorphAnalyzer()\n",
        "morph_vocab = MorphVocab()\n",
        "extractor = NamesExtractor(morph_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.6MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 13.4MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
            "Collecting natasha\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/8e/ab0745100be276750fb6b8858c6180a1756696572295a74eb5aea77f3bbd/natasha-1.4.0-py3-none-any.whl (34.4MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4MB 124kB/s \n",
            "\u001b[?25hRequirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
            "Collecting ipymarkup>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/9b/bf54c98d50735a4a7c84c71e92c5361730c878ebfe903d2c2d196ef66055/ipymarkup-0.9.0-py3-none-any.whl\n",
            "Collecting slovnet>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/3b/f1ef495be8990004959dd0510c95f688d1b07529f6a862bc56a405770b26/slovnet-0.5.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hCollecting razdel>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Collecting yargy>=0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/46/bc1a17200a55f4b0608f39ac64f1840fd4a52f9eeea462d9afecbf71246b/yargy-0.15.0-py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hCollecting navec>=0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/c1/771ec5565f0ce24874d7fd325b429f9caa80517a40d2e4ce5705120591f3/navec-0.10.0-py3-none-any.whl\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from slovnet>=0.3.0->natasha) (1.19.5)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26120 sha256=e722da128f6b773b29dee249f6b175322c46317bd2c34dd3177f1f98e0443c98\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: intervaltree, ipymarkup, razdel, navec, slovnet, yargy, natasha\n",
            "  Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBqwc1-NoMWQ",
        "outputId": "f17d247b-7344-4a62-a1ab-cd4dd26d60b8"
      },
      "source": [
        "! git clone https://github.com/Anna-Pon/SASemitents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SASemitents'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 23 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (23/23), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXULZZs5Mi8p"
      },
      "source": [
        "# Автоматизация работы с документами: извлечение сущностей и фактов из сообщений о раскрытии\n",
        "\n",
        "\n",
        "Задача:\n",
        "Собрать не менее 300 решений общих собраний участников (акционеров) с сайта e-disclosure.ru в формате .html страниц.\n",
        "Разработать инструмент по парсингу html страниц и извлечению из них текста решения.\n",
        "\n",
        "Разработать инструмент по извлечению из данных решений следующей информации:\n",
        "\n",
        "Полное и сокращенное наименование эмитента\n",
        "\n",
        "Адрес, ИНН, ОГРН эмитента\n",
        "\n",
        "Дата и форма собрания\n",
        "\n",
        "Наименование и ИНН утвержденного аудитора + тип отчетности, которую ему поручено проверять (при наличии)\n",
        "\n",
        "Утвержденный состав совета директоров (при наличии)\n",
        "\n",
        "Поднимался ли на собрании вопрос о выплате дивидендов и если да, то какое решение принято (3 варианта: “принято решение выплатить дивиденды”, “принято решение не выплачивать дивиденды”, “вопрос не поднимался”)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQlenkUZl4E7"
      },
      "source": [
        "# Сбор данных\n",
        "Данный раздел можно не запускать, табличка с собранными текстами отдельно подгружается далее"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjA0yy057rd9"
      },
      "source": [
        "#website_content = open('website.txt').read()\n",
        "website_content = open('/content/SASemitents/website.txt').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWTeejCgMM8r"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# распарсили страничку в дерево \n",
        "tree = BeautifulSoup(website_content, 'html.parser')\n",
        "table_with_links = tree.find_all('table', {'class': 'live noBorderTbl'})\n",
        "a_list = table_with_links[0].find_all('a')\n",
        "\n",
        "names_inds = list(np.arange(0, 1060, 2))\n",
        "links_inds = list(np.arange(1, 1060, 2))\n",
        "\n",
        "mapping_names = map(a_list. __getitem__, names_inds)\n",
        "mapping_links = map(a_list. __getitem__, links_inds)\n",
        "names  = list(mapping_names)\n",
        "links = list(mapping_links)\n",
        "\n",
        "parsed_table = pd.DataFrame({'company_name': names, 'link': links})\n",
        "\n",
        "parsed_table['company_name'] = parsed_table['company_name'].apply(lambda x: x.text)\n",
        "parsed_table['link'] = parsed_table['link'].apply(lambda x: str(x['href']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "rmho-r0bA4zs",
        "outputId": "d13cebaa-b20d-4901-bb60-3f79a72cb279"
      },
      "source": [
        "parsed_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company_name</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ПАО \"Бест Эффортс Банк\"</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ЗАО Агрофирма \"Нива\"</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ОАО \"ДОРСТРОЙ\"</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ООО КСН «Структурные инвестиции 1»</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ОАО \"КАНАТ\"</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>АО \"ЦГРМ \"ГЕНЕТИКО\"</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>ПАО \"ДИОД\"</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>ОАО \"ТСК\"</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>АО \"Смоленскмебель\"</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>ПАО \"ЧИФ Союзинвест\"</td>\n",
              "      <td>https://www.e-disclosure.ru/portal/event.aspx?...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>530 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           company_name                                               link\n",
              "0               ПАО \"Бест Эффортс Банк\"  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "1                  ЗАО Агрофирма \"Нива\"  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "2                        ОАО \"ДОРСТРОЙ\"  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "3    ООО КСН «Структурные инвестиции 1»  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "4                           ОАО \"КАНАТ\"  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "..                                  ...                                                ...\n",
              "525                 АО \"ЦГРМ \"ГЕНЕТИКО\"  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "526                          ПАО \"ДИОД\"  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "527                           ОАО \"ТСК\"  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "528                 АО \"Смоленскмебель\"  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "529                ПАО \"ЧИФ Союзинвест\"  https://www.e-disclosure.ru/portal/event.aspx?...\n",
              "\n",
              "[530 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbGcnO8JEgVL"
      },
      "source": [
        "def get_text(link):\n",
        "  response = requests.get(link).content\n",
        "  tree = BeautifulSoup(response, 'html.parser')\n",
        "  return tree.find_all('div', {'id': 'cont_wrap'})[0].find_all('div')[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DzVZ1ZEBCxWD"
      },
      "source": [
        "parsed_table['content'] = parsed_table['link'].apply(lambda x: get_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jDE_xYP_E1_X"
      },
      "source": [
        "parsed_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HX0NYI90JwOg"
      },
      "source": [
        "# parsed_table.to_excel('SAS project data.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-NjtgBZl8WN"
      },
      "source": [
        "# Вычленение информации из собранных данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v_JT-8_gT-Yi"
      },
      "source": [
        "parsed_table = pd.read_excel('/content/SASemitents/SAS_project_data.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNNS74AxJW_A"
      },
      "source": [
        "- #### Полное название, Сокращенное название, ОГРН, ИНН, Место нахождения эмитента"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XU9g_u1pyiiw"
      },
      "source": [
        "def get_name(x):\n",
        "  x = str(x)\n",
        "  ind = x.lower().find('полное фирменное наименование')\n",
        "  full_name = x[ind:x[ind:].find('<br/>')+ind - 1].split(')')[-1].strip('\\t').strip('\\r').strip('\\xa0').strip(':').strip('Полное фирменное наименование эмитент').strip(' : ').strip('\\t')\n",
        "  try:\n",
        "    if full_name[0] == 'у':\n",
        "      full_name = 'П' + full_name\n",
        "  except:\n",
        "    full_name = full_name\n",
        "  return full_name "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AQFFPDxizS5Y"
      },
      "source": [
        "parsed_table['Полное название'] = parsed_table['content'].apply(get_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nLIYtUISOHXv"
      },
      "source": [
        "parsed_table[parsed_table['Полное название'] == '']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7sfw78wAakZ5"
      },
      "source": [
        "parsed_table['Сокращенное название'] = parsed_table['company_name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lKm-3gDxPkB1"
      },
      "source": [
        "def get_full_name(text, lookup):\n",
        "  for br in str(text).split('<br/>'):\n",
        "    if lookup in br:\n",
        "      return br\n",
        "\n",
        "def points(text, lookup):\n",
        "  if ':' in text:\n",
        "    return text[text.find(':')+1:]\n",
        "  elif '\\t' in text:\n",
        "    return text[text.find('\\t')+1:]\n",
        "  else:\n",
        "    return text[text.find(lookup):]\n",
        "\n",
        "# parsed_table['Полное название'] = parsed_table['content'].apply(lambda x: points(get_full_name(x, 'Полное фирменное наименование эмитента'), 'Полное фирменное наименование эмитента').strip('\\r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h-wTM6bJhYT4"
      },
      "source": [
        "tolookfor='ИНН'\n",
        "parsed_table['ИНН'] = parsed_table.content.apply(lambda x: points(get_full_name(x, tolookfor), tolookfor).strip(' ').strip('\\r').strip('\\t').strip('\\xa0'))\n",
        "parsed_table['ИНН'] = parsed_table['ИНН'].apply(lambda x: x.replace('\\t', ' ').split(' ')[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yd642kxgjlEr"
      },
      "source": [
        "tolookfor='Место нахождения эмитента'\n",
        "parsed_table['Адрес'] = parsed_table.content.apply(lambda x: points(get_full_name(x, tolookfor), tolookfor).strip(' ').strip('\\r').strip('\\t').strip('\\xa0'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mEMYjEcxbMUP"
      },
      "source": [
        "'''\n",
        "tolookfor='ОГРН эмитента'\n",
        "parsed_table['ОГРН'] = parsed_table.content.apply(lambda x: points(get_full_name(x, tolookfor), tolookfor).strip(' ').strip('\\r').strip('\\t').strip('\\xa0'))\n",
        "parsed_table['ОГРН'] = parsed_table['ОГРН'].apply(lambda x: x.replace('\\t', ' ').split(' ')[-1]).astype(int)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CbD-WQ_c2AaE"
      },
      "source": [
        "def get_ogrn(x):\n",
        "  x = str(x)\n",
        "  ind = x.find('ОГРН эмитента')\n",
        "  ogrn = x[ind:x[ind:].find('<br/>')+ind].split('ОГРН эмитента')[-1].strip('\\t').strip('\\r').strip('\\xa0').strip(':').strip(' ').strip(';')\n",
        "  try:\n",
        "    ogrn = int(ogrn)\n",
        "  except:\n",
        "    ogrn = x[ind:x[ind:].replace('<br/>', 'XXXXX', 1).find('<br/>')+ind].split('ОГРН эмитента')[-1].strip('.<br/>').strip('\\t').strip('\\r').strip('\\xa0').strip(':').strip(' ')\n",
        "    try:\n",
        "      ogrn = int(ogrn)\n",
        "    except:\n",
        "      ogrn = x[ind:x[ind:].find('<br/>')+ind].split('–')[-1].strip('\\t').strip('\\r').strip('\\xa0').strip('-').strip(' ')\n",
        "  return ogrn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jiJIP_6q2PIB"
      },
      "source": [
        "parsed_table['ОГРН'] = parsed_table.content.apply(get_ogrn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_2jIY11JN99"
      },
      "source": [
        "- #### Дата проведения собрания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HD-QS65AIA8_"
      },
      "source": [
        "def find_date(x):\n",
        "  x = x.lower().replace('июля', '07').replace('августа', '08').replace('сентября', '09')\n",
        "  for i in x.split('<br/>'):\n",
        "    a = i.split('\\t')\n",
        "    for m in a:\n",
        "      if 'дата' in m:\n",
        "\n",
        "        try:\n",
        "          date = pd.to_datetime(i.strip('г.').strip('года').split()[-1], dayfirst=True)\n",
        "\n",
        "          if date.month < 7: # если выполняется, значит, увидел только год, либо не та дата\n",
        "            1/0 # просто ломаем код\n",
        "          if date.year < 2020: # если выполняется, значит, не та дата\n",
        "            break\n",
        "\n",
        "          return date\n",
        "\n",
        "        except:\n",
        "          i = i.replace('г.', ' г.') # вставим пробел там, где его не хватает, чтобы сплитить спокойно\n",
        "          date = '.'.join(i.split()[-4:-1]).replace('«', '').replace('»', '') # собираем составную дату\n",
        "\n",
        "          try:\n",
        "            date = pd.to_datetime(date, dayfirst=True) # проверяем, что datetime работает\n",
        "\n",
        "            if date.month == 1:\n",
        "              1/0\n",
        "            if date.year < 2020:\n",
        "              break\n",
        "\n",
        "            return date\n",
        "\n",
        "          except:\n",
        "            continue # если не нашел дату, идем дальше по циклу\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W4-t_Coc-WSC"
      },
      "source": [
        "parsed_table['Дата собрания'] = parsed_table.content.apply(find_date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pavTPvwSen9h"
      },
      "source": [
        "parsed_table[parsed_table['Дата собрания'].isna()]\n",
        "# 4 не достались, в них либо особенность - дата написана посреди предложения, либо там переход на новый абзац, \n",
        "# вообще можно добить, но вроде некритично"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VyDZI9U7oClL"
      },
      "source": [
        "parsed_table[parsed_table['Дата собрания'] < '2020-07-01'] # всё корректно досталось"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hjEFz2ZJo-C"
      },
      "source": [
        "- #### Форма собрания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zGF8YfeSJvpH"
      },
      "source": [
        "def find_form(x):\n",
        "  x = str(x).lower()\n",
        "  ind = -1 \n",
        "  look = ['форма проведения', 'форма поведения', 'общего собрания путем', 'общего собрания акционеров путем',\n",
        "          'форма и вид проведения', 'вид и форма общего собрания', 'форма собрания']\n",
        "  i=0\n",
        "  while ind == -1:\n",
        "    ind = x.find(look[i])\n",
        "    i+=1\n",
        "    if i >= len(look):\n",
        "      break\n",
        "\n",
        "\n",
        "  if (x.find('место проведения') != -1) or\\\n",
        "  (x.find('дата, место, время проведения') != -1) or\\\n",
        "  (x.find('дата, ме-сто, время проведения') != -1) or\\\n",
        "  (x.find('место (адрес) проведения') != -1) or\\\n",
        "  (x.find('личное присутствие') != -1) or\\\n",
        "  (x.find('будет проводиться по адресу') != -1):\n",
        "    return 'очное'\n",
        "  elif ind == -1:\n",
        "    return np.nan\n",
        "  else:\n",
        "    if (x[ind:].find('заочн') != -1) or (x[ind:].find('Заочн') != -1):\n",
        "      return 'заочное'\n",
        "    elif (x[ind:].find('совместное присутствие') != -1) or (x[ind:].find('совместного присутствия') != -1):\n",
        "      return 'очное'\n",
        "    else:\n",
        "      return np.nan\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1wU2IW1ZKaof"
      },
      "source": [
        "parsed_table['Форма собрания'] = parsed_table.content.apply(find_form)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ImrRQO67oTKE"
      },
      "source": [
        "parsed_table['Форма собрания'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B1EB9jqUQaA"
      },
      "source": [
        "- #### Дивиденды"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ov6MlAA3Voel"
      },
      "source": [
        "def div_agenda(x): # ищем, есть ли упоминание дивидендов в решении\n",
        "  x = str(x.lower())\n",
        "\n",
        "  if ('дивид' in x) or\\\n",
        "  ('распределение чистой прибыли' in x) or\\\n",
        "  ('о распределении чистой прибыли 'in x) or\\\n",
        "  ('распределение прибыли' in x):\n",
        "    return np.nan\n",
        "  else:\n",
        "    return 'вопрос не поднимался'\n",
        "\n",
        "\n",
        "def div_res(x): # проверяем решение по дивам\n",
        "  x = str(x).lower()\n",
        "  ind1 = x.find('не распред')\n",
        "  if ind1 == -1:\n",
        "    ind1 = x.find('не выплач')\n",
        "  if ind1 == -1:\n",
        "    ind1 = x.find('невыпла')\n",
        "  if ind1 == -1:\n",
        "    ind1 = x.find('не начисл')\n",
        "  if ind1 == -1:\n",
        "    ind1 = x.find('не производ')\n",
        "\n",
        "# смотрим, есть ли связь между отрицательным сказуемым и дивидендами, для этого задаем интервал, внутри которого должны находиться оба слова\n",
        "  ind2 = x[ind1- 400:ind1+400].find('дивид')\n",
        "  ind3 = x[ind1- 400:ind1+400].find('прибыль')\n",
        "  ind4 = x[ind1- 400:ind1+400].find('убыт')\n",
        "\n",
        "  if (ind1 != -1) and (ind2 != -1 or ind3 != -1 or ind4 != -1):\n",
        "    return 'принято решение не выплачивать дивиденды'\n",
        "  else:\n",
        "    return 'принято решение выплатить дивиденды'\n",
        "\n",
        "  # есть неточности, но в целом (примерно 90% достает корректно) очень даже неплохо работает"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IjnxgAqxUjnb"
      },
      "source": [
        "parsed_table['Дивиденды'] = parsed_table.content.apply(div_agenda)\n",
        "parsed_table.loc[parsed_table['Дивиденды'].isna(), 'Дивиденды'] = parsed_table[parsed_table['Дивиденды'].isna()].content.apply(div_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nc1syCJfCEx7"
      },
      "source": [
        "parsed_table['Дивиденды'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3pIezkIpP71"
      },
      "source": [
        "- #### Наименование и ИНН утвержденного аудитора "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UURS2VF-084v"
      },
      "source": [
        "found = parsed_table\n",
        "data = parsed_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HC4iXu1drYH3"
      },
      "source": [
        "indices = np.array([])\n",
        "for i in range(len(data)):\n",
        "    indices = np.append(indices, data['content'][i].lower().find('удитор'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QVflwKu8uzpj"
      },
      "source": [
        "found['Аудитор'] = ''\n",
        "found['Аудитор'][np.where(indices < 0)[0]] = 'Аудитора нет'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-W-QHWEsrkDu"
      },
      "source": [
        "signs_comp = ['ООО', 'ЗАО', 'ОАО', 'ПАО', 'Общество', 'АО'] # знаки для поиска компании\n",
        "punct = '#$%&\\()*,/:;<=>?@[\\\\]^_`{|}~' # белый шум\n",
        "# данная функция убирает из текста возможные наименования фирмы, которая нанимает аудитора\n",
        "def remove_comp_name(x, string):\n",
        "    comp = found['company_name'][x]\n",
        "    n = comp.count('\"')\n",
        "    if n > 2:\n",
        "        # если кавычек больше двух, то последние две заменим на другие\n",
        "        string = string.replace(comp.replace('\"', '«', n - 1).replace('\"', '»', 1), '')\n",
        "    # убираем название компании и все производные от него\n",
        "    string = string.replace(comp, '') \n",
        "    string = ' '.join(string.replace(comp.replace('№', ''), '').split())\n",
        "    string = ' '.join(string.replace('№', '').replace(comp, '').split())\n",
        "    string = string.replace(comp.replace('\"', '«', 1).replace('\"', '»', 1), '')\n",
        "    string = string.replace(comp.replace('«','\"').replace('»','\"'), '')\n",
        "    for elem in signs_comp:\n",
        "        comp = comp.replace(elem, '')\n",
        "    # убиарем пунктуацию\n",
        "    for i in range(len(punct)):\n",
        "        comp = comp.replace(punct[i], '')\n",
        "    comp = comp.strip()\n",
        "    # убираем еще варианты того, как можно переделать название компании\n",
        "    for elem in signs_comp:\n",
        "        string = string.replace(elem + ' ' + comp, '')\n",
        "    try:\n",
        "        string = string.replace(found['Полное название'][x].split('\"')[-2], '')\n",
        "    except:\n",
        "        try:\n",
        "            string = string.replace('«' + found['Полное название'][x].split('«')[-1], '')\n",
        "        except:\n",
        "            pass\n",
        "    # здесь учитываем случай, когда в названии компании делается ошибка (например, вместо русской с пишется английская c)\n",
        "    s = string.split()\n",
        "    n = len(comp.split())\n",
        "    for x in range(0, len(s) - n):\n",
        "        s2 = ' '.join(s[x:x + n])\n",
        "        # если расстояние между словами меньше 5 (то есть меньше 5 букв различается), то это название компании\n",
        "        if nltk.edit_distance(comp, s2) < 5:\n",
        "            del s[x: x + n]\n",
        "            break\n",
        "    string = ' '.join(s)\n",
        "    # убираем фирму реестр\n",
        "    return string.replace('ООО \"Реестр-РН\"', '').strip()\n",
        "\n",
        "# работаем с теми текстами, где есть вхождения:\n",
        "for i in np.where(indices != -1)[0]:\n",
        "    # находим все куски текста, где есть данные вхождения\n",
        "    t = [m.start() > [m.start() for m in re.finditer('удитор', data['content'][i].lower())][-1]\n",
        "                for m in re.finditer('<br/>', data['content'][i].lower())]\n",
        "    # убираем ту часть текста, которая до первого вхождения, и ту, которая после последнего вхождения (с некоторым интервалом)\n",
        "    left = [m.start() for m in re.finditer('<br/>', data['content'][i].lower())][list(compress(range(len(t)), t))[0] - 1]\n",
        "    right = [m.start() for m in re.finditer('<br/>', data['content'][i].lower())][list(compress(range(len(t)), t))[0] + 1]\n",
        "    # убираем разметку <br\\>\n",
        "    string = data['content'][i][left + 5:right - 1].replace('<br/>', '').replace('<br/', '')\n",
        "    # знаки для поиска аудитора\n",
        "    signs = ['ООО', 'ЗАО', 'ОАО', 'Акционерное', 'акционерное', 'Общество', 'общество', 'АО', \"АКЦИОНЕРНОЕ\"]\n",
        "    # удаляем название компании\n",
        "    string = remove_comp_name(i, string)\n",
        "    k = 0\n",
        "    string = string[:600]\n",
        "    # ищем последнее вхождение знака\n",
        "    for elem in signs:\n",
        "        c = string.rfind(elem)\n",
        "        if c > k:\n",
        "            k = c\n",
        "    string = string[k:]\n",
        "    # ищем кавычки, так как они находят фирмы\n",
        "    if len(string[:string.find('»') + 1]) > 0:\n",
        "        found['Аудитор'][i] = string[:string.find('»') + 1]\n",
        "    elif len(string[:string.replace('\"', ',', 2).find('\"') + 1]) > 0 and string.replace('\"', ',', 2).find('\"')  - string.replace('\"', ',', 1).find('\"')  < 25:\n",
        "        found['Аудитор'][i] = string[:string.replace('\"', ',',2 ).find('\"') + 1]\n",
        "    elif len(string[:string.replace('\"', ',', 1).find('\"') + 1]) > 0:\n",
        "        found['Аудитор'][i] = string[:string.replace('\"', ',', 1).find('\"') + 1]\n",
        "    elif len(string[string.find('«'):string.find('»') + 1]) > 0:\n",
        "        found['Аудитор'][i] = string[string.find('«'):string.find('»') + 1]\n",
        "    elif len(string[string.find('«'):string.find('\"') + 1]) > 0:\n",
        "        found['Аудитор'][i] = string[string.find('«') - 4:string.find('\"') + 1]\n",
        "    else:\n",
        "        found['Аудитор'][i] = string\n",
        "        k = 0\n",
        "    # если предыдущие правила не сработали, выводим доделать\n",
        "    if k == 0 or len(found['Аудитор'][i].split()) == 1:\n",
        "        found['Аудитор'][i] = 'Доделать'\n",
        "\n",
        "# второй цикл для тех текстов, где нужно доделать\n",
        "for i in np.where(found['Аудитор'] == 'Доделать')[0]:\n",
        "    # если вхождение ровно одно, то выводим, что аудитора нет, так как вхождений должно быть минимум 2 \n",
        "    # (упоминание в повестке дня и в отдельном рассмотрении)\n",
        "    if len([m.start() for m in re.finditer('удитор', data['content'][i].lower())]) == 1:\n",
        "        found['Аудитор'][i] = 'Аудитора нет'\n",
        "    # ищем все вхождения по текстам\n",
        "    t = [m.start() > [m.start() for m in re.finditer('удитор', data['content'][i].lower())][-1]\n",
        "            for m in re.finditer('<br/>', data['content'][i].lower())]\n",
        "    # в этот раз берем большее окно \n",
        "    left = [m.start() for m in re.finditer('<br/>', data['content'][i].lower())][list(compress(range(len(t)), t))[0] - 3]\n",
        "    right = [m.start() for m in re.finditer('<br/>', data['content'][i].lower())][list(compress(range(len(t)), t))[0] + 3]\n",
        "    # удаляем разметку\n",
        "    string = data['content'][i][left + 5:right - 1].replace('<br/>', '').replace('<br/', '')\n",
        "    # выписываем знаки и удаляем название компании\n",
        "    signs = ['ООО', 'ЗАО', 'ОАО', 'Акционерное', 'акционерное', 'Общество', 'общество', 'АО', \"АКЦИОНЕРНОЕ\"]\n",
        "    string = remove_comp_name(i, string)\n",
        "    # удаляем особые кейсы, когда фирма не раскрывает сведения (как ПАО Звезда):\n",
        "    if string.lower().find('не раскрываются') != -1:\n",
        "        found['Аудитор'][i] = 'Сведения не раскрываются'\n",
        "    # иначе ищем те куски текста, где есть выражение, рядом с которым обычно находятся названия фирм-аудиторов\n",
        "    else:\n",
        "        # убираем за против воздержался, так как они обычно в кавычках\n",
        "        string = string.lower().replace('«за»', '').replace('«против»', '').replace('«воздержался»', '')\n",
        "        # ищем фразу утвердить аудитором\n",
        "        string = string[string.lower().find('утвердить аудитором'):]\n",
        "        k = 0\n",
        "        # в данной подстроке ищем наки\n",
        "        for elem in signs:\n",
        "            c = string.rfind(elem)\n",
        "            if c > k:\n",
        "                k = c\n",
        "                break\n",
        "        string = string[k:]\n",
        "        # далее поиск аудитора по кавычкам\n",
        "        if len(string[:string.find('»') + 1]) > 0:\n",
        "            found['Аудитор'][i] = string[:string.find('»') + 1]\n",
        "        elif len(string[:string.replace('\"', ',', 2).find('\"') + 1]) > 0 and string.replace('\"', ',', 2).find('\"')  - string.replace('\"', ',', 1).find('\"')  < 25:\n",
        "            found['Аудитор'][i] = string[:string.replace('\"', ',',2 ).find('\"') + 1]\n",
        "        elif len(string[:string.replace('\"', ',', 1).find('\"') + 1]) > 0:\n",
        "            found['Аудитор'][i] = string[:string.replace('\"', ',', 1).find('\"') + 1]\n",
        "        elif len(string[string.find('«'):string.find('»') + 1]) > 0:\n",
        "            found['Аудитор'][i] = string[string.find('«'):string.find('»') + 1]\n",
        "        elif len(string[string.find('«'):string.find('\"') + 1]) > 0:\n",
        "            found['Аудитор'][i] = string[string.find('«') - 4:string.find('\"') + 1]\n",
        "        # если не сработали кавычки, ищем по пунктуации\n",
        "        elif len(string[:string.find(',') + 1]) > 0:\n",
        "            found['Аудитор'][i] = string[:string.find(',')]\n",
        "        else:\n",
        "            found['Аудитор'][i] = string\n",
        "            k = 0\n",
        "        # если ничего не нашли, то выводим доделать\n",
        "        if k == 0 or len(found['Аудитор'][i].split()) == 1:\n",
        "            found['Аудитор'][i] = 'Доделать'\n",
        "# обработка, чтобы все названия аудиторов выводились с большой буквы\n",
        "found['Аудитор'] = found['Аудитор'].apply(lambda x: re.sub('([а-яА-Я])', lambda x: x.groups()[0].upper(), x, 1).strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iwuQg_2JruNL"
      },
      "source": [
        "print('Нужно доделать:', len(np.where(found['Аудитор'] == 'Доделать')[0]))\n",
        "print('Всего текстов:', len(found))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mrLGfunur4fh"
      },
      "source": [
        "found['ИНН Аудитора'] = ' '\n",
        "for i in range(len(found)):\n",
        "    # ищем вхождения подстроки 'удитор'\n",
        "    try:\n",
        "        t = [m.start() > [m.start() for m in re.finditer('удитор', data['content'][i].lower())][-1]\n",
        "             for m in re.finditer('<br/>', data['content'][i].lower())]\n",
        "    except:\n",
        "        t = -29\n",
        "    if t != -29:\n",
        "        # если такие вхождения есть, то ищем куски текста с аудиторами\n",
        "        left = [m.start() for m in re.finditer('<br/>', data['content'][i].lower())][list(compress(range(len(t)), t))[0] - 1]\n",
        "        right = [m.start() for m in re.finditer('<br/>', data['content'][i].lower())][list(compress(range(len(t)), t))[0] + 1]\n",
        "        string = data['content'][i][left + 5:right - 1].replace('<br/>', '').replace('<br/', '')\n",
        "        # с помощью регулярного выражения ищем 10-значное число, рядом с которым есть слово ИНН\n",
        "        try:\n",
        "            found['ИНН Аудитора'][i] = int(re.findall(r'\\b\\d{10}\\b', string)[0]) * ('ИНН' in string)\n",
        "        except:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdZHQFgikf3_"
      },
      "source": [
        "- #### Совет Директоров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GlEVJyWOkt4I"
      },
      "source": [
        "data = parsed_table.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cHo503zikx53"
      },
      "source": [
        "def get_board(content):\n",
        "  ind = 0\n",
        "  text = ' '\n",
        "  i = 0\n",
        "  # если ничего не упоминается про совет директоров, то выбора тем более не было\n",
        "  if content.lower().find('совет директоров') == -1 and content.lower().find('совета директоров') == -1:\n",
        "      if content.lower().count('директор') <= 1 or (content.lower().count('совет директор') == 0 and content.lower().count('совета директор') == 0):\n",
        "        text = 'Вопрос не поднимался'\n",
        "  # иначе циклом ищем тот кусок текста, где есть совет директоров, но уже нет ревизионной комиссии\n",
        "  else:\n",
        "      while len(text) < 150:\n",
        "        x = content[ind + 10:]\n",
        "        ind = x.lower().find('совет директоров') + ind\n",
        "        if ind == -1:\n",
        "            ind = x.lower().find('совета директоров') + ind\n",
        "        if ind != -1 + ind:\n",
        "          ind1 = x[ind:].lower().find('ревизион') \n",
        "          if ind1 != -1:\n",
        "            text = x[ind:ind1+ind]\n",
        "          else:\n",
        "            ind1 = x[ind:].lower().find('аудитор')\n",
        "            if ind1 != -1:                                 \n",
        "              text = x[ind:ind1+ind] \n",
        "            else:\n",
        "              text = x[ind:] + ' '*100\n",
        "        elif ind == -1 and content.lower().count('директор') <= 1:\n",
        "              text = 'Вопрос не поднимался'\n",
        "        \n",
        "        # Это чтобы не допустить вечный цикл\n",
        "        else:\n",
        "          text = ' '*150\n",
        "        \n",
        "        i +=1\n",
        "        if i >= 10:\n",
        "          text = ' '*150\n",
        "      \n",
        "      # чтобы легче было увидеть ненайденные \n",
        "      if text == ' '*150:\n",
        "        text = np.nan\n",
        "\n",
        "      # проверка, чтобы точно не обрабатывать потом куски, где нет совета директоров\n",
        "      if text == np.nan:\n",
        "        ind = 0\n",
        "        ind = content.lower().find('совет директоров') + ind\n",
        "        if ind == -1:\n",
        "            ind = content.lower().find('совета директоров') + ind\n",
        "        if ind == -1 and content.lower().count('директор') <= 1:\n",
        "            text = 'Вопрос не поднимался'\n",
        "        #if type(text) != 'str':\n",
        "        #    text = 'Доделать'\n",
        "      # предобработка\n",
        "      text = str(text)\n",
        "      text = text.replace('<br/>', ' ')\n",
        "      text = text.replace('\\t', ' ')\n",
        "      text = text.replace('\\t0', ' ')\n",
        "      text = text.replace('\\xa0', ' ')\n",
        "      text = ' '.join(re.sub( r\"([А-Я])\", r\" \\1\", text).split())\n",
        "      replace_list = ['Итог', 'Решение', 'Вопрос', 'Фамилия', 'Число', 'Дата', 'За', 'Против', 'Воздержался', 'Общество', 'Банк', 'Предложение', 'Результат', 'Формулировка', 'Идентификационный', 'Договор', 'Бывший', 'Бест', 'Предоставить', 'Избравший', 'Уполномоченное']\n",
        "      text = re.sub(r'|'.join(map(re.escape, replace_list)), ' ', text)\n",
        "      if text != 'Вопрос не поднимался' and text != np.nan:\n",
        "          text = sent_tokenize(text)\n",
        "          text = np.unique(text)\n",
        "\n",
        "      if np.isscalar(text) != True:\n",
        "          text = ' '.join(text)\n",
        "          matches = extractor(text)\n",
        "          facts = [_.fact for _ in matches if (_.fact.first != None and _.fact.last != None)]\n",
        "          dir = []\n",
        "          for fact in facts:\n",
        "            try:\n",
        "              last = py2.parse(fact.last)[0].inflect({'sing', 'nomn'}).word.capitalize()\n",
        "            except:\n",
        "              last = fact.last\n",
        "            try:\n",
        "              first = py2.parse(fact.first)[0].inflect({'sing', 'nomn'}).word.capitalize()\n",
        "            except:\n",
        "              first = fact.first\n",
        "            try:\n",
        "              middle = py2.parse(fact.middle)[0].inflect({'sing', 'nomn'}).word.capitalize()\n",
        "            except:\n",
        "              try:\n",
        "                middle = fact.middle\n",
        "              except:\n",
        "                middle = str()\n",
        "            person = last + ' ' + first \n",
        "            if middle != None:\n",
        "              person = person + ' ' + middle\n",
        "            dir.append(person)\n",
        "      text = dir\n",
        "      if len(text) <= 1:\n",
        "        text = 'Вопрос не поднимался'\n",
        "      if np.isscalar(text) != True:\n",
        "        text = np.unique(text)\n",
        "  # возвращаем список людей, которые были избраны в совет директоров\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TbdHBYxXk1IG"
      },
      "source": [
        "# вытащим СД\n",
        "data['Совет директоров'] = data.content.apply(get_board)\n",
        "\n",
        "# Так как у нас нет разметки, а пустых ячеек тоже нет, то сложно судить о качестве данной модели, но в случайной выборке из 10 наблюдений все списки оказались верными."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X19gnxR2yV9x"
      },
      "source": [
        "# в презу - вопрос не поднимался + 36, 49, 196, 161, 54, 284, 357, 242, 307, 157, 408, 259, 251, 511, 514, 456\n",
        "#data.drop(columns = ['content'], inplace = True)\n",
        "i = 197\n",
        "data[i:i + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ2ui4o7mYKi"
      },
      "source": [
        "### Что еще нужно собрать:\n",
        "\n",
        "~~Дата собрания~~\n",
        "\n",
        "~~Форма собрания~~\n",
        "\n",
        "~~Наименование и ИНН утвержденного аудитора~~\n",
        "\n",
        "~~Утвержденный состав совета директоров (при наличии)~~\n",
        "\n",
        "~~Поднимался ли на собрании вопрос о выплате дивидендов и если да, то какое решение принято (3 варианта: “принято решение выплатить дивиденды”, “принято решение не выплачивать дивиденды”, “вопрос не поднимался”)~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QwZUxMaLnJEl"
      },
      "source": [
        "# parsed_table.to_excel('parsed and found.xlsx', index=False)\n",
        "# partial_res = pd.read_excel('/content/SASemitents/parsed_and_found.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MkqbY5jNMPz-"
      },
      "source": [
        "data.drop(columns = ['content'], inplace = True)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zeyV_yiYmMZB"
      },
      "source": [
        "data.to_excel(\"prs.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OivFeGbMwCk-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}